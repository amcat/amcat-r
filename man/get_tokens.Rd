% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/corpus.r
\name{get_tokens}
\alias{get_tokens}
\title{Get Tokens from AmCAT}
\usage{
get_tokens(project = NULL, articleset = NULL, conn = conn_from_env(),
  module = "elastic", filters = NULL, page_size = 1, sentence = NULL,
  only_cached = F, ...)
}
\arguments{
\item{project}{id of the project containing the tokens}

\item{articleset}{id of the articleset to get features from. If not specified, specify sentence for 'ad hoc' parsing}

\item{conn}{the connection object from \code{\link{amcat_connect}}}

\item{module}{the NLP preprocessing module to get the tokens from}

\item{filters}{Additional filters, ie c(pos1="V", pos1="A") to select only verbs and adjectives}

\item{page_size}{the number of features (articles?) to include per call}

\item{sentence}{a sentence (string) to be parsed if articleset id is not given}

\item{only_cached}{if true, only get tokens that have already been preprocessed (recommended for large corpora!)}

\item{...}{additional arguments to get_pages}
}
\value{
A data frame of tokens
}
\description{
Get Tokens (pos, lemma etc) from AmCAT
}
