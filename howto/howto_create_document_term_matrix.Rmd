Importing AmCAT articles as tokens and creating a document-term matrix
===============================================
  
The AmCAT API has an endpoint for downloading token frequencies per document.
This allows for corpus linguistic analyses such as frequency analysis, collocations, corpus comparisons, and topic modeling. 

For these types of text analysis (bag-of-word approaches) the common way to organize data is in a document-term matrix (DTM).
In this howto we demonstrate how to import tokens from AmCAT into R and create a DTM.

We use the DocumentTermMatrix class of the [tm](http://cran.r-project.org/web/packages/tm/vignettes/tm.pdf) package. 
Since the `tm` package is quite popular, its DocumentTermMatrix class is compatible with various packages for text analysis. 
The `tm` package is not a dependency for amcat-r, so it first needs to be loaded separately.

```{r}
library(tm)
```

Requesting tokens
-----------------

When downloading token frequencies, one usually wants lemmatized and/or POS-tagged tokens.
This means that the word 'means' is analysed as a verb (POS) with lemma mean.
Technically, this linguistic processing is performed by AmCAT using [xTas](www.xtas.net), 
which means that the first time a document is requested with a certain analysis it is cached,
so asking the same document again does not cause processing to be repeated.

Tokens are requested from the `projects/articleset/ID/tokens` endpoint, 
specifying the set and analysis module to use. 
Currently, the useful modules are `corenlp_lemmatize` for English (default) and `tadpole` for Dutch. 

*Note*: As of May 2014, the vocabulary analysis features are not yet available through 
the production version of amcat (release 3.3). 
However, [preview.amcat.nl](http://preview.amcat.nl)
gives access to the same database using the newest development version of AmCAT.
Therefore, this howto connects to that server rather than the default server:
  
```{r message=FALSE}
library(amcatr)
conn = amcat.connect("http://preview.amcat.nl")
t = amcat.gettokens(conn, project=442, articleset=10271, module="corenlp_lemmatize",
                    page_size=1, npages=1)              
tail(t, n=10)
```

The command displayed above requests the tokens for a single article by setting `page_size` to 1 and requesting only a single page.
In the output you can see that it gives the frequency per word per article, and gives lemma and pos information. 
For example, the last word `your` has lemma `you` and POS possessive pronoun (`PRP$`). 
The `pos1` column gives a simplified POS tag, with `N` for nouns, `V` for verbs, `A` for adjectives, and `M` for proper names. 

If we want to get the term frequencies for a larger set of articles, 
it can be useful to select only the data we really need. 
The following command requests all tokens for the publicly available set 10271 
containing wikinews articles on Iraq.
It filters on 'substantive' POS tags N (noun), M (name), V (verb), and A (adjective), 
and only downloads the lemma per article:
  
```{r message=FALSE}
t = amcat.gettokens(conn, project=442, articleset=10271, module="corenlp_lemmatize", 
                    page_size=100, npages=100, 
                    filters=c(pos1="N", pos1="M", pos1="V", pos1="M"))
head(t, n=10)
```


Document-Term Matrix
--------------------

The token data as imported above can easily be transformed into a dtm. 
For this we first create a sparse matrix using the xtabs function, and then transform it to a dtm using the `tm` function, `as.DocumentTermMatrix`.
For this we need a vector for the tokens (terms), together with a vector indicating in which documents the token occured (ids) and how often (freqs).

```{r, message=F}
t$freq = 1
dtm = xtabs(freq ~ aid + lemma, t, sparse=T)
dtm = as.DocumentTermMatrix(dtm, weighting = weightTf)
```

Match document meta
--------------------

For many purposes it is usefull to include the document meta, 
such as the medium in which an article was published and the date at which it was published. 

The document meta can be imported from amcat with the `amcat.getarticlemeta` function. 

```{r}
meta = amcat.getarticlemeta(conn, set=10271, dateparts=T)
head(meta)
```

```{r}
meta = meta[match(rownames(dtm), meta$id),]
dim(dtm)
dim(meta)
```


Performing analysis with the dtm
--------------------

The dtm is a common data structure for a variety of computational text analysis applications. Many of these types of analysis are also covered in other R packages, such as:
* [corpustools](https://github.com/kasperwelbers/corpus-tools).
* [rTextTools](https://journal.r-project.org/archive/2013-1/collingwood-jurka-boydstun-etal.pdf).
* [semnet](https://github.com/kasperwelbers/semnet).

